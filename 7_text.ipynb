{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: wget: command not found\n",
      "tar: Option --skip-old-files is not supported\n",
      "Usage:\n",
      "  List:    tar -tf <archive-filename>\n",
      "  Extract: tar -xf <archive-filename>\n",
      "  Create:  tar -cf <archive-filename> [filenames...]\n",
      "  Help:    tar --help\n"
     ]
    }
   ],
   "source": [
    "#! wget -nc http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz -P data\n",
    "#Get data on that link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: tree: command not found\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!tree -dL 2 data/aclImdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import numpy as np\n",
    "review_train = load_files('allmm/train/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type text_train: <class 'list'>\n",
      "length text_train: 75000\n",
      "text_train[1]:\n",
      "b\"Amount of disappointment I am getting these days seeing movies like Partner, Jhoom Barabar and now, Heyy Babyy is gonna end my habit of seeing first day shows.<br /><br />The movie is an utter disappointment because it had the potential to become a laugh riot only if the d\\xc3\\xa9butant director, Sajid Khan hadn't tried too many things. Only saving grace in the movie were the last thirty minutes, which were seriously funny elsewhere the movie fails miserably. First half was desperately been tried to look funny but wasn't. Next 45 minutes were emotional and looked totally artificial and illogical.<br /><br />OK, when you are out for a movie like this you don't expect much logic but all the flaws tend to appear when you don't enjoy the movie and thats the case with Heyy Babyy. Acting is good but thats not enough to keep one interested.<br /><br />For the positives, you can take hot actresses, last 30 minutes, some comic scenes, good acting by the lead cast and the baby. Only problem is that these things do not come together properly to make a good movie.<br /><br />Anyways, I read somewhere that It isn't a copy of Three men and a baby but I think it would have been better if it was.\"\n"
     ]
    }
   ],
   "source": [
    "text_train,y_train = review_train.data,review_train.target\n",
    "print('type text_train: {}'.format(type(text_train)))\n",
    "print('length text_train: {}'.format(len(text_train)))\n",
    "print('text_train[1]:\\n{}'.format(text_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = [doc.replace(b\"<br />\",b\" \")for doc in text_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_train[1]:\n",
      "b\"Amount of disappointment I am getting these days seeing movies like Partner, Jhoom Barabar and now, Heyy Babyy is gonna end my habit of seeing first day shows.  The movie is an utter disappointment because it had the potential to become a laugh riot only if the d\\xc3\\xa9butant director, Sajid Khan hadn't tried too many things. Only saving grace in the movie were the last thirty minutes, which were seriously funny elsewhere the movie fails miserably. First half was desperately been tried to look funny but wasn't. Next 45 minutes were emotional and looked totally artificial and illogical.  OK, when you are out for a movie like this you don't expect much logic but all the flaws tend to appear when you don't enjoy the movie and thats the case with Heyy Babyy. Acting is good but thats not enough to keep one interested.  For the positives, you can take hot actresses, last 30 minutes, some comic scenes, good acting by the lead cast and the baby. Only problem is that these things do not come together properly to make a good movie.  Anyways, I read somewhere that It isn't a copy of Three men and a baby but I think it would have been better if it was.\"\n"
     ]
    }
   ],
   "source": [
    "print('text_train[1]:\\n{}'.format(text_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples quantity to class(train): [12500 12500 50000]\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples quantity to class(train): {}\".format(np.bincount(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type text_test: <class 'list'>\n",
      "length text_test: 25000\n",
      "text_test[1]:\n",
      "[12500 12500]\n"
     ]
    }
   ],
   "source": [
    "review_test = load_files('allmm/test/')\n",
    "text_test,y_test = review_test.data,review_test.target\n",
    "text_test = [doc.replace(b\"<br />\",b\" \")for doc in text_test]\n",
    "print('type text_test: {}'.format(type(text_test)))\n",
    "print('length text_test: {}'.format(len(text_test)))\n",
    "print('text_test[1]:\\n{}'.format(np.bincount(y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAG OF WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bards_words = ['The fool doth thinks he is wise,', 'but the wise man knows himself to be fool']\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "vect.fit(bards_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:13\n",
      "Vocabulary content:\n",
      "{'the': 9, 'fool': 3, 'doth': 2, 'thinks': 10, 'he': 4, 'is': 6, 'wise': 12, 'but': 1, 'man': 8, 'knows': 7, 'himself': 5, 'to': 11, 'be': 0}\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulary size:{}'.format(len(vect.vocabulary_)))\n",
    "print('Vocabulary content:\\n{}'.format(vect.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag_of_words:<2x13 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "bag_of_words = vect.transform(bards_words)\n",
    "print('bag_of_words:{}'.format(repr(bag_of_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not sparce bag_of_words:\n",
      "[[0 0 1 1 1 0 1 0 0 1 1 0 1]\n",
      " [1 1 0 1 0 1 0 1 1 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print('not sparce bag_of_words:\\n{}'.format(bag_of_words.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "<75000x124255 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 10315542 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer().fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "print('X_train:\\n{}'.format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features quantity: 124255\n",
      "First 20 features:\n",
      "['00', '000', '0000', '0000000000000000000000000000000001', '0000000000001', '000000001', '000000003', '00000001', '000001745', '00001', '0001', '00015', '0002', '0007', '00083', '000ft', '000s', '000th', '001', '002']\n",
      "Feature from 20010 to 20030:\n",
      "\n",
      "Every 2000 th feature:\n",
      "['00', '_require_', 'aideed', 'announcement', 'asteroid', 'banquière', 'besieged', 'bollwood', 'btvs', 'carboni', 'chcialbym', 'clotheth', 'consecration', 'cringeful', 'deadness', 'devagan', 'doberman', 'duvall', 'endocrine', 'existent', 'fetiches', 'formatted', 'garard', 'godlie', 'gumshoe', 'heathen', 'honoré', 'immatured', 'interested', 'jewelry', 'kerchner', 'köln', 'leydon', 'lulu', 'mardjono', 'meistersinger', 'misspells', 'mumblecore', 'ngah', 'oedpius', 'overwhelmingly', 'penned', 'pleading', 'previlage', 'quashed', 'recreating', 'reverent', 'ruediger', 'sceme', 'settling', 'silveira', 'soderberghian', 'stagestruck', 'subprime', 'tabloids', 'themself', 'tpf', 'tyzack', 'unrestrained', 'videoed', 'weidler', 'worrisomely', 'zombified']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "print('Features quantity: {}'.format(len(feature_names)))\n",
    "print('First 20 features:\\n{}'.format(feature_names[:20]))\n",
    "print('Feature from 20010 to 20030:\\n'.format(feature_names[20010:20030]))\n",
    "print('Every 2000 th feature:\\n{}'.format(feature_names[::2000]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vlad3d/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/vlad3d/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/vlad3d/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average correctness with cross validation: 0.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "scores = cross_val_score(LogisticRegression(),X_train,y_train,cv=5)\n",
    "#print(scores)\n",
    "print('Average correctness with cross validation: {:.2f}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C':[0.001,0.01,0.1,1,10]}\n",
    "grid = GridSearchCV(LogisticRegression(),param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print('Best value of cross validation: {:.2f}'.format(grid.best_score_))\n",
    "print('Best parameters: ', grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vect.transform(text_test)\n",
    "print('Correctness on the test set: {:.2f}'.format(grid.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df=5).fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "print('X_train x min_df: {}'.format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "print('Features quantity: {}'.format(len(feature_names)))\n",
    "print('First 50 features:\\n{}'.format(feature_names[:50]))\n",
    "print('Feature from 20010 to 20030:\\n'.format(feature_names[20010:20030]))\n",
    "print('Every 700 th feature:\\n{}'.format(feature_names[::700]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(LogisticRegression(),param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print('Best value of cross validation: {:.2f}'.format(grid.best_score_))\n",
    "print('Best parameters: ', grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STOP-WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "print('Stop-words quantity:{}'.format(len(ENGLISH_STOP_WORDS)))\n",
    "print('Every 10th stop-words:\\n{}'.format(list(ENGLISH_STOP_WORDS)[::10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CounterVectorizer(min_df=5,stop_words='english').fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "print('X_train with stop-words using:\\n{}'.format(repr(X_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(LogisticRegression(),param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print('Best value of cross validation: {:.2f}'.format(grid.best_score_))\n",
    "print('Best parameters: ', grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfifdVectorizer\n",
    "from sklern.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(TfidfVectorizer(min_df=5, norm=None), LogisticRegression())\n",
    "param_grid = {'logisticregression__C':[0.001,0.01,0.1,1,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(LogisticRegression(),param_grid, cv=5)\n",
    "grid.fit(text_train, y_train)\n",
    "print('Best value of cross validation: {:.2f}'.format(grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = grid.best_estimator_.named_steps['tfidfvectorizer']\n",
    "X_train = vectorizer.transform(text_train)\n",
    "max_value = X_train.max(axis=0).toarray().ravel()\n",
    "sort_by_tfidf = max_value.argsort()\n",
    "feature_names = np.array(vectorizer.get_feature_names())\n",
    "print('Feature with small tfidf:\\n{}'.format(feature_names[sorted_by_tfidf[:20]]))\n",
    "print('Feature with bigger tfidf:\\n{}'.format(feature_names[sorted_by_tfidf[-20:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_idf = np.argsort(vectorizer.idf_)\n",
    "print('Features with the small values idf:\\n{}'.format(feature_names[sorted_by_idf[:100]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.tools.visualize_coefficients(\n",
    "grid.best_estimator_.named_steps['logisticregression'].coef_,\n",
    "feature_names,n_top_features = 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAG OF WORDS (N-GRAMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('bards_words:\\n{}'.format(bards_words))\n",
    "cv = CounterVectorizer(ngram_range=(1,1)).fit(bards_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dictionary size:{}'.format(len(cv.vocabulary_)))\n",
    "print('Dictionary:\\n{}'.format(cv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CounterVectorizer(ngram_range=(2,2)).fit(bards_words)\n",
    "print('Dictionary size:{}'.format(len(cv.vocabulary_)))\n",
    "print('Dictionary:\\n{}'.format(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data(not sparce):\\n{}'.format(cv.transform(bards_words).toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CounterVectorizer(ngram_range=(1,3)).fit(bards_words)\n",
    "print('Dictionary size:{}'.format(len(cv.vocabulary_)))\n",
    "print('Dictionary:\\n{}'.format(cv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(TfidVectorizer(min_df=5), LogisticRegression())\n",
    "param_grid = {\"logisticregression__C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "\"tfidfvectorizer__ngram_range\": [(1, 1), (1, 2), (1, 3)]}\n",
    "grid = GridSearchCV(pipe,param_grid, cv=5)\n",
    "grid.fit(text_train, y_train)\n",
    "print('Best value of cross validation: {:.2f}'.format(grid.best_score_))\n",
    "print('Best params:\\n{}'.format(grid.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = grid.cv_results_['mean_test_score'].reshape(-1,3).T\n",
    "heatmap = mglearn.tools.heatmap(\n",
    "scores,xlabel = 'C', ylabel = 'ngram_range', cmap = 'viridis', fmt='%.3f',\n",
    "xticklabels = param_grid['logisticregression__C'], \n",
    "    yticklabels=param_grid['tfidfvectorizer_ngram_range'])\n",
    "plt.colorbar(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = grid.best_estimator_.named_steps['tfidfvectorizer']\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "coef = grid.best_estimator_.named_steps['logisticregression'].coef_\n",
    "mglearn.tools.visualize_coefficients(coef, feature_names,n_top_features = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array([len(feature.split(\" \")) for feature in feature_names]) == 3\n",
    "mglearn.tools.visualize_coefficients(coef.ravel()[mask],feature_names[mask],n_top_features = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEMMING LEMATIZATION\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "en_nlp = spacy.load('en')\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "def compare_normalization(doc):\n",
    "    doc_spacy = en_nlp(doc)\n",
    "    print('Lemmatization')\n",
    "    print([token.lemma_ for token in doc_spacy])\n",
    "    print('Stemming')\n",
    "    print([stemmer.stem(token.norm_.lower()) for token in doc_spacy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_normalization(u\"Our meeting today was worse than yesterday, \" \"I'm scared of meeting the clients tomorrow.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regexp = re.compile('(?u)\\\\b\\\\w\\\\w+\\\\b')\n",
    "en_nlp = spacy.load('en')\n",
    "old_tokenizer = en_nlp.tokenizer\n",
    "en_nlp.tokenizer = lambda string: old_tokenizer.tokens_from_list(regexp.findall(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(document):\n",
    "    doc_spacy = en_nlp(document,entity=False, parse=False)\n",
    "    return[token.lemma_ for token in doc_spacy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_vect = CounterVectorizer(tokenizer=custom_tokenizer,min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lemma = lemma_vect.fit_transform(text_train)\n",
    "print('shape X_train lemma: {}'.format(X_train_lemma.shape))\n",
    "vect = CounterVectorizer(min_df=5).fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "print('X_train shape: {}'.format(X_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "param_grid = {'C':[0.001,0.01,0.1,1,10]}\n",
    "cv = StratifiedShuffleSplit(n_iter=5, test_size=0.99, train_size=0.01,random_state=0)\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=cv)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best value cross validation: {:.3f}'.format(grid.best_score_))\n",
    "grid.fit(X_train_lemma, y_train)\n",
    "print('Best value cross validation (lemmatization): {:.3f}'.format(grid.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIRICHLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CounterVectorizer(max_features = 10000, max_df=.15)\n",
    "X = vect.fit_transform(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_topics=10, learn_method='batch', max_iter=25, random_state=0)\n",
    "document_topics = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting = np.argsort(lda.components_, axis=1)[:,::-1]\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "mglearn.tools.print_topics(topics=range(10), feature_names=feature_names, sorting=sorting, \n",
    "                          topics_per_chunk=5, n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda100 = LatentDirichletAllocation(n_topics=100, learn_method='batch', max_iter=25, random_state=0)\n",
    "document_topics100 = lda100.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = np.array([7, 16, 24, 25, 28, 36, 37, 45, 51, 53, 54, 63, 89, 97])\n",
    "sorting = np.argsort(lda100.components_, axis=1)[:,::-1]\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "mglearn.tools.print_topics(topics=topics, feature_names=feature_names, sorting=sorting, \n",
    "                          topics_per_chunk=5, n_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music = np.argsort(document_topics100[:,45])[::-1]\n",
    "for i in music[:10]:\n",
    "    print(b\".\".join(text_train[i].split(b\". \")[:2])+b\".\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
    "topic_names = [\"{:>2} \".format(i) + \" \".join(words)\n",
    "               for i, words in enumerate(feature_names[sorting[:, :2]])]\n",
    "for col in [0,1]:\n",
    "    start = col * 50\n",
    "    end = (col + 1) * 50\n",
    "    ax[col].barh(np.arange(50), np.sum(document_topics100, axis=0)[start:end])\n",
    "    ax[col].set_yticks(np.arange(50))\n",
    "    ax[col].set_yticklabels(topic_names[start:end], ha=\"left\", va=\"top\")\n",
    "    ax[col].invert_yaxis()\n",
    "    ax[col].set_xlim(0, 2000)\n",
    "    yax = ax[col].get_yaxis()\n",
    "    yax.set_tick_params(pad=130)\n",
    "plt.tight_layout()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
